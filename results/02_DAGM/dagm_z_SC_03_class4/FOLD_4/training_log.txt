2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 Executing run with path ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 AREA_RATIO_MIN            : 0.9
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 BATCH_SIZE                : 8
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 CONTINUE_LAST_TRAIN       : None
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 DATASET                   : DAGM
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 DATASET_PATH              : ./datasets/DAGM/
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 DELTA_CLS_LOSS            : 1.0
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 DILATE                    : 0
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 DROPOUT_P                 : 0.4
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 DYN_BALANCED_LOSS         : False
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 EPOCHS                    : 67
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 FOLD                      : 4
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 FREQUENCY_SAMPLING        : True
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 GPU                       : 0
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 GRADIENT_ADJUSTMENT       : False
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 INPUT_CHANNELS            : 1
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 INPUT_HEIGHT              : 512
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 INPUT_WIDTH               : 512
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 LEARNING_RATE             : 0.04
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 LOSS_SEG_THR              : 0.02
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 MEMORY_FIT                : 8
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 MODEL_NAME                : models_trans10
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 NUM_SEGMENTED             : 0
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 ON_DEMAND_READ            : False
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 OPTIMIZER                 : SGD
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 REPRODUCIBLE_RUN          : True
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 RESULTS_PATH              : ./results_new
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 SAMPLING                  : half_mixed
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 SAVE_IMAGES               : True
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 TRAIN_NUM                 : None
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 TRANS_BRIGHT              : 1.0
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 TRANS_KEEP_LOOP           : 1
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 TRANS_NUM                 : 4
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 USE_BEST_MODEL            : False
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 VALIDATE                  : True
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 VALIDATE_ON_TEST          : True
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 VALIDATION_N_EPOCHS       : 3
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 VOLUME_CFG                : None
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 WEIGHTED_SEG_LOSS         : False
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 WEIGHTED_SEG_LOSS_MAX     : 10.0
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 WEIGHTED_SEG_LOSS_P       : 1.0
2022-10-01 22:23:18	dagm_z_SC_03_class4_FOLD_4 Reproducible run, fixing all seeds to:1337
This is models_trans10
2022-10-01 22:23:37	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:23:37	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:23:44	dagm_z_SC_03_class4_FOLD_4 Epoch 1/67 ==> avg_loss_seg=0.70358, avg_loss_seg_pos=0.17573, avg_loss_dec=1.18926, avg_loss=1.89283, FP=37, FN=46, correct=77/160, in 7.18s/epoch
2022-10-01 22:23:50	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.427573, and AP=0.097599, with best thr=0.598424 at f-measure=0.212 and FP=505, FN=0, TOTAL SAMPLES=575, avg_loss_seg_neg=0.65922, avg_loss_seg_pos=0.66076
2022-10-01 22:23:50	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_01.pth
2022-10-01 22:23:50	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\best_state_dict.pth
2022-10-01 22:23:50	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:23:50	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:23:56	dagm_z_SC_03_class4_FOLD_4 Epoch 2/67 ==> avg_loss_seg=0.63006, avg_loss_seg_pos=0.15870, avg_loss_dec=0.71223, avg_loss=1.34229, FP=45, FN=35, correct=80/160, in 5.53s/epoch
2022-10-01 22:23:56	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:23:56	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:24:01	dagm_z_SC_03_class4_FOLD_4 Epoch 3/67 ==> avg_loss_seg=0.57259, avg_loss_seg_pos=0.14520, avg_loss_dec=0.70369, avg_loss=1.27628, FP=34, FN=45, correct=81/160, in 5.48s/epoch
2022-10-01 22:24:01	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:24:01	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:24:07	dagm_z_SC_03_class4_FOLD_4 Epoch 4/67 ==> avg_loss_seg=0.52404, avg_loss_seg_pos=0.13397, avg_loss_dec=0.73069, avg_loss=1.25473, FP=46, FN=42, correct=72/160, in 5.48s/epoch
2022-10-01 22:24:13	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.515228, and AP=0.164089, with best thr=0.495160 at f-measure=0.234 and FP=136, FN=41, TOTAL SAMPLES=575, avg_loss_seg_neg=0.50006, avg_loss_seg_pos=0.51336
2022-10-01 22:24:13	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_04.pth
2022-10-01 22:24:13	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\best_state_dict.pth
2022-10-01 22:24:13	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:24:13	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:24:19	dagm_z_SC_03_class4_FOLD_4 Epoch 5/67 ==> avg_loss_seg=0.48185, avg_loss_seg_pos=0.12434, avg_loss_dec=0.73026, avg_loss=1.21211, FP=43, FN=41, correct=76/160, in 5.50s/epoch
2022-10-01 22:24:19	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:24:19	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:24:24	dagm_z_SC_03_class4_FOLD_4 Epoch 6/67 ==> avg_loss_seg=0.44410, avg_loss_seg_pos=0.11563, avg_loss_dec=0.69486, avg_loss=1.13896, FP=37, FN=35, correct=88/160, in 5.51s/epoch
2022-10-01 22:24:24	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:24:24	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:24:30	dagm_z_SC_03_class4_FOLD_4 Epoch 7/67 ==> avg_loss_seg=0.41028, avg_loss_seg_pos=0.10785, avg_loss_dec=0.71909, avg_loss=1.12937, FP=44, FN=33, correct=83/160, in 5.51s/epoch
2022-10-01 22:24:36	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.627712, and AP=0.268066, with best thr=0.477462 at f-measure=0.294 and FP=19, FN=53, TOTAL SAMPLES=575, avg_loss_seg_neg=0.39468, avg_loss_seg_pos=0.41769
2022-10-01 22:24:36	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_07.pth
2022-10-01 22:24:36	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\best_state_dict.pth
2022-10-01 22:24:36	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:24:36	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:24:42	dagm_z_SC_03_class4_FOLD_4 Epoch 8/67 ==> avg_loss_seg=0.38028, avg_loss_seg_pos=0.10085, avg_loss_dec=0.69215, avg_loss=1.07242, FP=36, FN=37, correct=87/160, in 5.53s/epoch
2022-10-01 22:24:42	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:24:42	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:24:47	dagm_z_SC_03_class4_FOLD_4 Epoch 9/67 ==> avg_loss_seg=0.35530, avg_loss_seg_pos=0.09516, avg_loss_dec=0.68588, avg_loss=1.04119, FP=36, FN=37, correct=87/160, in 5.53s/epoch
2022-10-01 22:24:47	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:24:47	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:24:53	dagm_z_SC_03_class4_FOLD_4 Epoch 10/67 ==> avg_loss_seg=0.33302, avg_loss_seg_pos=0.09033, avg_loss_dec=0.71230, avg_loss=1.04532, FP=45, FN=33, correct=82/160, in 5.60s/epoch
2022-10-01 22:24:59	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.647668, and AP=0.356377, with best thr=0.510386 at f-measure=0.367 and FP=12, FN=50, TOTAL SAMPLES=575, avg_loss_seg_neg=0.32207, avg_loss_seg_pos=0.35064
2022-10-01 22:24:59	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_10.pth
2022-10-01 22:24:59	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\best_state_dict.pth
2022-10-01 22:24:59	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:24:59	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:25:05	dagm_z_SC_03_class4_FOLD_4 Epoch 11/67 ==> avg_loss_seg=0.31233, avg_loss_seg_pos=0.08559, avg_loss_dec=0.67346, avg_loss=0.98579, FP=34, FN=29, correct=97/160, in 5.52s/epoch
2022-10-01 22:25:05	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:25:05	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:25:11	dagm_z_SC_03_class4_FOLD_4 Epoch 12/67 ==> avg_loss_seg=0.29366, avg_loss_seg_pos=0.08122, avg_loss_dec=0.67030, avg_loss=0.96396, FP=38, FN=32, correct=90/160, in 5.53s/epoch
2022-10-01 22:25:11	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:25:11	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:25:16	dagm_z_SC_03_class4_FOLD_4 Epoch 13/67 ==> avg_loss_seg=0.27613, avg_loss_seg_pos=0.07647, avg_loss_dec=0.64209, avg_loss=0.91822, FP=28, FN=33, correct=99/160, in 5.52s/epoch
2022-10-01 22:25:22	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.911620, and AP=0.767163, with best thr=0.298755 at f-measure=0.721 and FP=3, FN=28, TOTAL SAMPLES=575, avg_loss_seg_neg=0.26613, avg_loss_seg_pos=0.29758
2022-10-01 22:25:22	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_13.pth
2022-10-01 22:25:22	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\best_state_dict.pth
2022-10-01 22:25:22	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:25:22	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:25:28	dagm_z_SC_03_class4_FOLD_4 Epoch 14/67 ==> avg_loss_seg=0.26064, avg_loss_seg_pos=0.07424, avg_loss_dec=0.66226, avg_loss=0.92290, FP=36, FN=26, correct=98/160, in 5.54s/epoch
2022-10-01 22:25:28	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:25:28	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:25:34	dagm_z_SC_03_class4_FOLD_4 Epoch 15/67 ==> avg_loss_seg=0.24673, avg_loss_seg_pos=0.07021, avg_loss_dec=0.62161, avg_loss=0.86833, FP=22, FN=33, correct=105/160, in 5.54s/epoch
2022-10-01 22:25:34	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:25:34	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:25:39	dagm_z_SC_03_class4_FOLD_4 Epoch 16/67 ==> avg_loss_seg=0.23332, avg_loss_seg_pos=0.06761, avg_loss_dec=0.63163, avg_loss=0.86495, FP=26, FN=29, correct=105/160, in 5.54s/epoch
2022-10-01 22:25:45	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.961974, and AP=0.882794, with best thr=0.542341 at f-measure=0.848 and FP=8, FN=12, TOTAL SAMPLES=575, avg_loss_seg_neg=0.22671, avg_loss_seg_pos=0.26161
2022-10-01 22:25:45	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_16.pth
2022-10-01 22:25:45	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\best_state_dict.pth
2022-10-01 22:25:45	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:25:45	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:25:51	dagm_z_SC_03_class4_FOLD_4 Epoch 17/67 ==> avg_loss_seg=0.22141, avg_loss_seg_pos=0.06410, avg_loss_dec=0.54730, avg_loss=0.76872, FP=24, FN=21, correct=115/160, in 5.54s/epoch
2022-10-01 22:25:51	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:25:51	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:25:57	dagm_z_SC_03_class4_FOLD_4 Epoch 18/67 ==> avg_loss_seg=0.21274, avg_loss_seg_pos=0.06280, avg_loss_dec=0.58246, avg_loss=0.79520, FP=26, FN=29, correct=105/160, in 5.54s/epoch
2022-10-01 22:25:57	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:25:57	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:26:03	dagm_z_SC_03_class4_FOLD_4 Epoch 19/67 ==> avg_loss_seg=0.20173, avg_loss_seg_pos=0.06084, avg_loss_dec=0.56843, avg_loss=0.77016, FP=21, FN=29, correct=110/160, in 5.55s/epoch
2022-10-01 22:26:08	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.950255, and AP=0.829360, with best thr=0.542370 at f-measure=0.779 and FP=1, FN=24, TOTAL SAMPLES=575, avg_loss_seg_neg=0.19591, avg_loss_seg_pos=0.23828
2022-10-01 22:26:08	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_19.pth
2022-10-01 22:26:08	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:26:08	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:26:14	dagm_z_SC_03_class4_FOLD_4 Epoch 20/67 ==> avg_loss_seg=0.19356, avg_loss_seg_pos=0.05916, avg_loss_dec=0.55051, avg_loss=0.74407, FP=21, FN=25, correct=114/160, in 5.55s/epoch
2022-10-01 22:26:14	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:26:14	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:26:20	dagm_z_SC_03_class4_FOLD_4 Epoch 21/67 ==> avg_loss_seg=0.18300, avg_loss_seg_pos=0.05684, avg_loss_dec=0.55307, avg_loss=0.73607, FP=19, FN=26, correct=115/160, in 5.54s/epoch
2022-10-01 22:26:20	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:26:20	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:26:26	dagm_z_SC_03_class4_FOLD_4 Epoch 22/67 ==> avg_loss_seg=0.17451, avg_loss_seg_pos=0.05415, avg_loss_dec=0.44879, avg_loss=0.62330, FP=14, FN=21, correct=125/160, in 5.54s/epoch
2022-10-01 22:26:32	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.993880, and AP=0.964897, with best thr=0.589293 at f-measure=0.902 and FP=5, FN=8, TOTAL SAMPLES=575, avg_loss_seg_neg=0.16970, avg_loss_seg_pos=0.21090
2022-10-01 22:26:32	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_22.pth
2022-10-01 22:26:32	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\best_state_dict.pth
2022-10-01 22:26:32	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:26:32	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:26:37	dagm_z_SC_03_class4_FOLD_4 Epoch 23/67 ==> avg_loss_seg=0.16842, avg_loss_seg_pos=0.05382, avg_loss_dec=0.51685, avg_loss=0.68527, FP=21, FN=26, correct=113/160, in 5.54s/epoch
2022-10-01 22:26:37	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:26:37	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:26:43	dagm_z_SC_03_class4_FOLD_4 Epoch 24/67 ==> avg_loss_seg=0.16035, avg_loss_seg_pos=0.05262, avg_loss_dec=0.38589, avg_loss=0.54624, FP=12, FN=12, correct=136/160, in 5.54s/epoch
2022-10-01 22:26:43	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:26:43	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:26:49	dagm_z_SC_03_class4_FOLD_4 Epoch 25/67 ==> avg_loss_seg=0.15197, avg_loss_seg_pos=0.04982, avg_loss_dec=0.37834, avg_loss=0.53031, FP=12, FN=15, correct=133/160, in 5.55s/epoch
2022-10-01 22:26:55	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.977434, and AP=0.917138, with best thr=0.487156 at f-measure=0.859 and FP=13, FN=7, TOTAL SAMPLES=575, avg_loss_seg_neg=0.14837, avg_loss_seg_pos=0.19413
2022-10-01 22:26:55	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_25.pth
2022-10-01 22:26:55	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:26:55	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:27:01	dagm_z_SC_03_class4_FOLD_4 Epoch 26/67 ==> avg_loss_seg=0.14527, avg_loss_seg_pos=0.04816, avg_loss_dec=0.37724, avg_loss=0.52251, FP=13, FN=15, correct=132/160, in 5.55s/epoch
2022-10-01 22:27:01	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:27:01	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:27:06	dagm_z_SC_03_class4_FOLD_4 Epoch 27/67 ==> avg_loss_seg=0.14189, avg_loss_seg_pos=0.04728, avg_loss_dec=0.37116, avg_loss=0.51305, FP=12, FN=14, correct=134/160, in 5.55s/epoch
2022-10-01 22:27:06	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:27:06	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:27:12	dagm_z_SC_03_class4_FOLD_4 Epoch 28/67 ==> avg_loss_seg=0.13564, avg_loss_seg_pos=0.04641, avg_loss_dec=0.31804, avg_loss=0.45368, FP=9, FN=11, correct=140/160, in 5.55s/epoch
2022-10-01 22:27:18	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.996026, and AP=0.980233, with best thr=0.337896 at f-measure=0.955 and FP=2, FN=4, TOTAL SAMPLES=575, avg_loss_seg_neg=0.13177, avg_loss_seg_pos=0.18513
2022-10-01 22:27:18	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_28.pth
2022-10-01 22:27:18	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\best_state_dict.pth
2022-10-01 22:27:18	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:27:18	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:27:24	dagm_z_SC_03_class4_FOLD_4 Epoch 29/67 ==> avg_loss_seg=0.12881, avg_loss_seg_pos=0.04545, avg_loss_dec=0.21633, avg_loss=0.34514, FP=1, FN=8, correct=151/160, in 5.55s/epoch
2022-10-01 22:27:24	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:27:24	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:27:29	dagm_z_SC_03_class4_FOLD_4 Epoch 30/67 ==> avg_loss_seg=0.12766, avg_loss_seg_pos=0.04712, avg_loss_dec=0.43557, avg_loss=0.56323, FP=16, FN=18, correct=126/160, in 5.55s/epoch
2022-10-01 22:27:29	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:27:29	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:27:35	dagm_z_SC_03_class4_FOLD_4 Epoch 31/67 ==> avg_loss_seg=0.11923, avg_loss_seg_pos=0.04340, avg_loss_dec=0.25276, avg_loss=0.37200, FP=4, FN=11, correct=145/160, in 5.54s/epoch
2022-10-01 22:27:41	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.998782, and AP=0.991365, with best thr=0.355293 at f-measure=0.947 and FP=1, FN=6, TOTAL SAMPLES=575, avg_loss_seg_neg=0.11621, avg_loss_seg_pos=0.17185
2022-10-01 22:27:41	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_31.pth
2022-10-01 22:27:41	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\best_state_dict.pth
2022-10-01 22:27:41	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:27:41	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:27:47	dagm_z_SC_03_class4_FOLD_4 Epoch 32/67 ==> avg_loss_seg=0.11437, avg_loss_seg_pos=0.04159, avg_loss_dec=0.19107, avg_loss=0.30544, FP=2, FN=9, correct=149/160, in 5.55s/epoch
2022-10-01 22:27:47	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:27:47	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:27:53	dagm_z_SC_03_class4_FOLD_4 Epoch 33/67 ==> avg_loss_seg=0.10941, avg_loss_seg_pos=0.04151, avg_loss_dec=0.22886, avg_loss=0.33827, FP=3, FN=7, correct=150/160, in 5.55s/epoch
2022-10-01 22:27:53	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:27:53	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:27:58	dagm_z_SC_03_class4_FOLD_4 Epoch 34/67 ==> avg_loss_seg=0.10551, avg_loss_seg_pos=0.04023, avg_loss_dec=0.24462, avg_loss=0.35013, FP=9, FN=10, correct=141/160, in 5.55s/epoch
2022-10-01 22:28:04	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.999913, and AP=0.999359, with best thr=0.167111 at f-measure=0.986 and FP=2, FN=0, TOTAL SAMPLES=575, avg_loss_seg_neg=0.10579, avg_loss_seg_pos=0.16868
2022-10-01 22:28:04	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_34.pth
2022-10-01 22:28:04	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\best_state_dict.pth
2022-10-01 22:28:04	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:28:04	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:28:10	dagm_z_SC_03_class4_FOLD_4 Epoch 35/67 ==> avg_loss_seg=0.10290, avg_loss_seg_pos=0.04064, avg_loss_dec=0.16771, avg_loss=0.27061, FP=3, FN=8, correct=149/160, in 5.55s/epoch
2022-10-01 22:28:10	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:28:10	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:28:16	dagm_z_SC_03_class4_FOLD_4 Epoch 36/67 ==> avg_loss_seg=0.10023, avg_loss_seg_pos=0.03942, avg_loss_dec=0.21670, avg_loss=0.31693, FP=3, FN=9, correct=148/160, in 5.54s/epoch
2022-10-01 22:28:16	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:28:16	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:28:22	dagm_z_SC_03_class4_FOLD_4 Epoch 37/67 ==> avg_loss_seg=0.09532, avg_loss_seg_pos=0.03862, avg_loss_dec=0.14249, avg_loss=0.23782, FP=3, FN=6, correct=151/160, in 5.55s/epoch
2022-10-01 22:28:28	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.993677, and AP=0.954148, with best thr=0.938896 at f-measure=0.892 and FP=9, FN=6, TOTAL SAMPLES=575, avg_loss_seg_neg=0.09621, avg_loss_seg_pos=0.15069
2022-10-01 22:28:28	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_37.pth
2022-10-01 22:28:28	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:28:28	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:28:33	dagm_z_SC_03_class4_FOLD_4 Epoch 38/67 ==> avg_loss_seg=0.09308, avg_loss_seg_pos=0.03805, avg_loss_dec=0.17741, avg_loss=0.27049, FP=5, FN=8, correct=147/160, in 5.55s/epoch
2022-10-01 22:28:33	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:28:33	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:28:39	dagm_z_SC_03_class4_FOLD_4 Epoch 39/67 ==> avg_loss_seg=0.09116, avg_loss_seg_pos=0.03716, avg_loss_dec=0.11031, avg_loss=0.20147, FP=1, FN=3, correct=156/160, in 5.54s/epoch
2022-10-01 22:28:39	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:28:39	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:28:45	dagm_z_SC_03_class4_FOLD_4 Epoch 40/67 ==> avg_loss_seg=0.08813, avg_loss_seg_pos=0.03666, avg_loss_dec=0.29026, avg_loss=0.37839, FP=5, FN=8, correct=147/160, in 5.55s/epoch
2022-10-01 22:28:51	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.425339, and AP=0.096824, with best thr=0.286088 at f-measure=0.214 and FP=501, FN=0, TOTAL SAMPLES=575, avg_loss_seg_neg=0.10034, avg_loss_seg_pos=0.17156
2022-10-01 22:28:51	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_40.pth
2022-10-01 22:28:51	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:28:51	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:28:56	dagm_z_SC_03_class4_FOLD_4 Epoch 41/67 ==> avg_loss_seg=0.10665, avg_loss_seg_pos=0.04513, avg_loss_dec=0.84695, avg_loss=0.95359, FP=33, FN=41, correct=86/160, in 5.55s/epoch
2022-10-01 22:28:56	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:28:56	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:29:02	dagm_z_SC_03_class4_FOLD_4 Epoch 42/67 ==> avg_loss_seg=0.10330, avg_loss_seg_pos=0.04463, avg_loss_dec=0.76326, avg_loss=0.86656, FP=36, FN=38, correct=86/160, in 5.55s/epoch
2022-10-01 22:29:02	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:29:02	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:29:08	dagm_z_SC_03_class4_FOLD_4 Epoch 43/67 ==> avg_loss_seg=0.09854, avg_loss_seg_pos=0.04362, avg_loss_dec=0.69624, avg_loss=0.79478, FP=37, FN=33, correct=90/160, in 5.55s/epoch
2022-10-01 22:29:14	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.813842, and AP=0.543016, with best thr=0.412301 at f-measure=0.513 and FP=19, FN=38, TOTAL SAMPLES=575, avg_loss_seg_neg=0.09844, avg_loss_seg_pos=0.17430
2022-10-01 22:29:14	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_43.pth
2022-10-01 22:29:14	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:29:14	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:29:20	dagm_z_SC_03_class4_FOLD_4 Epoch 44/67 ==> avg_loss_seg=0.09384, avg_loss_seg_pos=0.04255, avg_loss_dec=0.53675, avg_loss=0.63059, FP=23, FN=16, correct=121/160, in 5.55s/epoch
2022-10-01 22:29:20	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:29:20	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:29:25	dagm_z_SC_03_class4_FOLD_4 Epoch 45/67 ==> avg_loss_seg=0.09168, avg_loss_seg_pos=0.04169, avg_loss_dec=0.38918, avg_loss=0.48086, FP=11, FN=11, correct=138/160, in 5.55s/epoch
2022-10-01 22:29:25	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:29:25	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:29:31	dagm_z_SC_03_class4_FOLD_4 Epoch 46/67 ==> avg_loss_seg=0.08296, avg_loss_seg_pos=0.03791, avg_loss_dec=0.29996, avg_loss=0.38292, FP=9, FN=10, correct=141/160, in 5.55s/epoch
2022-10-01 22:29:37	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.999565, and AP=0.996968, with best thr=0.666199 at f-measure=0.978 and FP=1, FN=2, TOTAL SAMPLES=575, avg_loss_seg_neg=0.08128, avg_loss_seg_pos=0.15020
2022-10-01 22:29:37	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_46.pth
2022-10-01 22:29:37	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:29:37	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:29:43	dagm_z_SC_03_class4_FOLD_4 Epoch 47/67 ==> avg_loss_seg=0.08167, avg_loss_seg_pos=0.03784, avg_loss_dec=0.37104, avg_loss=0.45271, FP=10, FN=15, correct=135/160, in 5.55s/epoch
2022-10-01 22:29:43	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:29:43	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:29:49	dagm_z_SC_03_class4_FOLD_4 Epoch 48/67 ==> avg_loss_seg=0.07679, avg_loss_seg_pos=0.03615, avg_loss_dec=0.22292, avg_loss=0.29971, FP=2, FN=11, correct=147/160, in 5.55s/epoch
2022-10-01 22:29:49	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:29:49	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:29:54	dagm_z_SC_03_class4_FOLD_4 Epoch 49/67 ==> avg_loss_seg=0.07489, avg_loss_seg_pos=0.03525, avg_loss_dec=0.16813, avg_loss=0.24302, FP=1, FN=6, correct=153/160, in 5.55s/epoch
2022-10-01 22:30:00	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.999072, and AP=0.994118, with best thr=0.642061 at f-measure=0.971 and FP=3, FN=1, TOTAL SAMPLES=575, avg_loss_seg_neg=0.07314, avg_loss_seg_pos=0.14345
2022-10-01 22:30:00	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_49.pth
2022-10-01 22:30:00	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:30:00	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:30:06	dagm_z_SC_03_class4_FOLD_4 Epoch 50/67 ==> avg_loss_seg=0.07208, avg_loss_seg_pos=0.03533, avg_loss_dec=0.13294, avg_loss=0.20502, FP=3, FN=5, correct=152/160, in 5.55s/epoch
2022-10-01 22:30:06	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:30:06	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:30:12	dagm_z_SC_03_class4_FOLD_4 Epoch 51/67 ==> avg_loss_seg=0.07548, avg_loss_seg_pos=0.03735, avg_loss_dec=0.34500, avg_loss=0.42048, FP=12, FN=13, correct=135/160, in 5.55s/epoch
2022-10-01 22:30:12	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:30:12	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:30:18	dagm_z_SC_03_class4_FOLD_4 Epoch 52/67 ==> avg_loss_seg=0.06935, avg_loss_seg_pos=0.03513, avg_loss_dec=0.14837, avg_loss=0.21772, FP=1, FN=5, correct=154/160, in 5.55s/epoch
2022-10-01 22:30:23	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.999391, and AP=0.995490, with best thr=0.299593 at f-measure=0.964 and FP=4, FN=1, TOTAL SAMPLES=575, avg_loss_seg_neg=0.06807, avg_loss_seg_pos=0.13723
2022-10-01 22:30:23	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_52.pth
2022-10-01 22:30:23	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:30:23	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:30:29	dagm_z_SC_03_class4_FOLD_4 Epoch 53/67 ==> avg_loss_seg=0.06800, avg_loss_seg_pos=0.03531, avg_loss_dec=0.18932, avg_loss=0.25731, FP=3, FN=8, correct=149/160, in 5.55s/epoch
2022-10-01 22:30:29	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:30:29	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:30:35	dagm_z_SC_03_class4_FOLD_4 Epoch 54/67 ==> avg_loss_seg=0.06686, avg_loss_seg_pos=0.03399, avg_loss_dec=0.07346, avg_loss=0.14031, FP=0, FN=3, correct=157/160, in 5.55s/epoch
2022-10-01 22:30:35	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:30:35	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:30:41	dagm_z_SC_03_class4_FOLD_4 Epoch 55/67 ==> avg_loss_seg=0.06441, avg_loss_seg_pos=0.03411, avg_loss_dec=0.20834, avg_loss=0.27274, FP=3, FN=9, correct=148/160, in 5.55s/epoch
2022-10-01 22:30:46	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.999797, and AP=0.998454, with best thr=0.238052 at f-measure=0.986 and FP=2, FN=0, TOTAL SAMPLES=575, avg_loss_seg_neg=0.06343, avg_loss_seg_pos=0.13556
2022-10-01 22:30:46	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_55.pth
2022-10-01 22:30:47	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:30:47	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:30:52	dagm_z_SC_03_class4_FOLD_4 Epoch 56/67 ==> avg_loss_seg=0.06340, avg_loss_seg_pos=0.03386, avg_loss_dec=0.11327, avg_loss=0.17667, FP=1, FN=3, correct=156/160, in 5.55s/epoch
2022-10-01 22:30:52	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:30:52	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:30:58	dagm_z_SC_03_class4_FOLD_4 Epoch 57/67 ==> avg_loss_seg=0.06237, avg_loss_seg_pos=0.03422, avg_loss_dec=0.11678, avg_loss=0.17915, FP=0, FN=6, correct=154/160, in 5.55s/epoch
2022-10-01 22:30:58	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:30:58	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:31:04	dagm_z_SC_03_class4_FOLD_4 Epoch 58/67 ==> avg_loss_seg=0.06052, avg_loss_seg_pos=0.03326, avg_loss_dec=0.06849, avg_loss=0.12901, FP=0, FN=3, correct=157/160, in 5.55s/epoch
2022-10-01 22:31:10	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.999710, and AP=0.997861, with best thr=0.215272 at f-measure=0.978 and FP=3, FN=0, TOTAL SAMPLES=575, avg_loss_seg_neg=0.05996, avg_loss_seg_pos=0.13262
2022-10-01 22:31:10	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_58.pth
2022-10-01 22:31:10	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:31:10	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:31:15	dagm_z_SC_03_class4_FOLD_4 Epoch 59/67 ==> avg_loss_seg=0.05941, avg_loss_seg_pos=0.03319, avg_loss_dec=0.07910, avg_loss=0.13851, FP=2, FN=2, correct=156/160, in 5.54s/epoch
2022-10-01 22:31:15	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:31:15	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:31:21	dagm_z_SC_03_class4_FOLD_4 Epoch 60/67 ==> avg_loss_seg=0.05873, avg_loss_seg_pos=0.03299, avg_loss_dec=0.07384, avg_loss=0.13257, FP=0, FN=4, correct=156/160, in 5.54s/epoch
2022-10-01 22:31:21	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:31:21	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:31:27	dagm_z_SC_03_class4_FOLD_4 Epoch 61/67 ==> avg_loss_seg=0.05763, avg_loss_seg_pos=0.03272, avg_loss_dec=0.09295, avg_loss=0.15057, FP=2, FN=4, correct=154/160, in 5.55s/epoch
2022-10-01 22:31:33	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.999826, and AP=0.998712, with best thr=0.248557 at f-measure=0.986 and FP=2, FN=0, TOTAL SAMPLES=575, avg_loss_seg_neg=0.05677, avg_loss_seg_pos=0.13133
2022-10-01 22:31:33	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_61.pth
2022-10-01 22:31:33	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:31:33	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:31:39	dagm_z_SC_03_class4_FOLD_4 Epoch 62/67 ==> avg_loss_seg=0.05632, avg_loss_seg_pos=0.03237, avg_loss_dec=0.08453, avg_loss=0.14085, FP=0, FN=4, correct=156/160, in 5.55s/epoch
2022-10-01 22:31:39	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:31:39	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:31:44	dagm_z_SC_03_class4_FOLD_4 Epoch 63/67 ==> avg_loss_seg=0.05666, avg_loss_seg_pos=0.03264, avg_loss_dec=0.12608, avg_loss=0.18274, FP=2, FN=4, correct=154/160, in 5.54s/epoch
2022-10-01 22:31:44	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:31:44	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:31:50	dagm_z_SC_03_class4_FOLD_4 Epoch 64/67 ==> avg_loss_seg=0.05471, avg_loss_seg_pos=0.03236, avg_loss_dec=0.09871, avg_loss=0.15342, FP=2, FN=4, correct=154/160, in 5.55s/epoch
2022-10-01 22:31:56	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=0.999275, and AP=0.994812, with best thr=0.452254 at f-measure=0.963 and FP=2, FN=3, TOTAL SAMPLES=575, avg_loss_seg_neg=0.05391, avg_loss_seg_pos=0.13023
2022-10-01 22:31:56	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_64.pth
2022-10-01 22:31:56	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:31:56	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:32:02	dagm_z_SC_03_class4_FOLD_4 Epoch 65/67 ==> avg_loss_seg=0.05383, avg_loss_seg_pos=0.03261, avg_loss_dec=0.08854, avg_loss=0.14237, FP=2, FN=3, correct=155/160, in 5.54s/epoch
2022-10-01 22:32:02	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:32:02	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:32:07	dagm_z_SC_03_class4_FOLD_4 Epoch 66/67 ==> avg_loss_seg=0.05322, avg_loss_seg_pos=0.03250, avg_loss_dec=0.15037, avg_loss=0.20359, FP=4, FN=6, correct=150/160, in 5.54s/epoch
2022-10-01 22:32:07	dagm_z_SC_03_class4_FOLD_4 Returning seg_loss_weight 1 and dec_loss_weight 1.0
2022-10-01 22:32:07	dagm_z_SC_03_class4_FOLD_4 Returning dec_gradient_multiplier 1
2022-10-01 22:32:13	dagm_z_SC_03_class4_FOLD_4 Epoch 67/67 ==> avg_loss_seg=0.05302, avg_loss_seg_pos=0.03269, avg_loss_dec=0.16514, avg_loss=0.21816, FP=4, FN=6, correct=150/160, in 5.55s/epoch
2022-10-01 22:32:19	dagm_z_SC_03_class4_FOLD_4 VALIDATION || AUC=1.000000, and AP=1.000000, with best thr=0.130709 at f-measure=1.000 and FP=0, FN=0, TOTAL SAMPLES=575, avg_loss_seg_neg=0.05215, avg_loss_seg_pos=0.13162
2022-10-01 22:32:19	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\ep_67.pth
2022-10-01 22:32:19	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\best_state_dict.pth
now best_AP=0.9999999999999998,epoch=67
2022-10-01 22:32:19	dagm_z_SC_03_class4_FOLD_4 Saving current models state to ./results_new\DAGM\dagm_z_SC_03_class4\FOLD_4\models\final_state_dict.pth
2022-10-01 22:32:19	dagm_z_SC_03_class4_FOLD_4 Keeping same model state
dagm_z_SC_03_class4_FOLD_4 EVAL AUC=1.000000, and AP=1.000000, w/ best thr=0.130709 at f-m=1.000 and FP=0, FN=0
run_time 13.4min	
